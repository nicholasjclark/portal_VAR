// Stan model code for the GAM-VAR model in Clark et al 2023
// (generated by package mvgam)
functions {
  /* Function to compute the matrix square root */
  /* see Heaps 2022 for details (https://doi.org/10.1080/10618600.2022.2079648)*/
  matrix sqrtm(matrix A) {
    int m = rows(A);
    vector[m] root_root_evals = sqrt(sqrt(eigenvalues_sym(A)));
    matrix[m, m] evecs = eigenvectors_sym(A);
    matrix[m, m] eprod = diag_post_multiply(evecs, root_root_evals);
    return tcrossprod(eprod);
  }
  /* Function to transform P_real to P */
  /* see Heaps 2022 for details (https://doi.org/10.1080/10618600.2022.2079648)*/
  matrix P_realtoP(matrix P_real) {
    int m = rows(P_real);
    matrix[m, m] B = tcrossprod(P_real);
    for (i in 1 : m) 
      B[i, i] += 1.0;
    return mdivide_left_spd(sqrtm(B), P_real);
  }
  /* Function to perform the reverse mapping*/
  /* see Heaps 2022 for details (https://doi.org/10.1080/10618600.2022.2079648)*/
  array[,] matrix rev_mapping(array[] matrix P, matrix Sigma) {
    int p = size(P);
    int m = rows(Sigma);
    array[p, p] matrix[m, m] phi_for;
    array[p, p] matrix[m, m] phi_rev;
    array[p + 1] matrix[m, m] Sigma_for;
    array[p + 1] matrix[m, m] Sigma_rev;
    matrix[m, m] S_for;
    matrix[m, m] S_rev;
    array[p + 1] matrix[m, m] S_for_list;
    array[p + 1] matrix[m, m] Gamma_trans;
    array[2, p] matrix[m, m] phiGamma;
    // Step 1:
    Sigma_for[p + 1] = Sigma;
    S_for_list[p + 1] = sqrtm(Sigma);
    for (s in 1 : p) {
      // In this block of code S_rev is B^{-1} and S_for is a working matrix
      S_for = -tcrossprod(P[p - s + 1]);
      for (i in 1 : m) 
        S_for[i, i] += 1.0;
      S_rev = sqrtm(S_for);
      S_for_list[p - s + 1] = mdivide_right_spd(mdivide_left_spd(S_rev,
                                                                 sqrtm(
                                                                 quad_form_sym(
                                                                 Sigma_for[
                                                                 p - s + 2],
                                                                 S_rev))),
                                                S_rev);
      Sigma_for[p - s + 1] = tcrossprod(S_for_list[p - s + 1]);
    }
    // Step 2:
    Sigma_rev[1] = Sigma_for[1];
    Gamma_trans[1] = Sigma_for[1];
    for (s in 0 : (p - 1)) {
      S_for = S_for_list[s + 1];
      S_rev = sqrtm(Sigma_rev[s + 1]);
      phi_for[s + 1, s + 1] = mdivide_right_spd(S_for * P[s + 1], S_rev);
      phi_rev[s + 1, s + 1] = mdivide_right_spd(S_rev * P[s + 1]', S_for);
      Gamma_trans[s + 2] = phi_for[s + 1, s + 1] * Sigma_rev[s + 1];
      if (s >= 1) {
        for (k in 1 : s) {
          phi_for[s + 1, k] = phi_for[s, k]
                              - phi_for[s + 1, s + 1] * phi_rev[s, s - k + 1];
          phi_rev[s + 1, k] = phi_rev[s, k]
                              - phi_rev[s + 1, s + 1] * phi_for[s, s - k + 1];
        }
        for (k in 1 : s) 
          Gamma_trans[s + 2] = Gamma_trans[s + 2]
                               + phi_for[s, k] * Gamma_trans[s + 2 - k];
      }
      Sigma_rev[s + 2] = Sigma_rev[s + 1]
                         - quad_form_sym(Sigma_for[s + 1],
                                         phi_rev[s + 1, s + 1]');
    }
    for (i in 1 : p) 
      phiGamma[1, i] = phi_for[p, i];
    for (i in 1 : p) 
      phiGamma[2, i] = Gamma_trans[i]';
    return phiGamma;
  }
}
data {
  int<lower=0> total_obs; // total number of observations
  int<lower=0> n; // number of timepoints per series
  int<lower=0> n_sp_trend; // number of trend smoothing parameters
  int<lower=0> n_lv; // number of dynamic factors
  int<lower=0> n_series; // number of series
  matrix[n_series, n_lv] Z; // matrix mapping series to latent states
  int<lower=0> num_basis; // total number of basis coefficients
  int<lower=0> num_basis_trend; // number of trend basis coefficients
  vector[num_basis_trend] zero_trend; // prior locations for trend basis coefficients
  matrix[total_obs, num_basis] X; // mgcv GAM design matrix
  matrix[n * n_lv, num_basis_trend] X_trend; // trend model design matrix
  array[n, n_series] int<lower=0> ytimes; // time-ordered matrix (which col in X belongs to each [time, series] observation?)
  array[n, n_lv] int<lower=0> ytimes_trend; // time-ordered matrix for latent states
  int<lower=0> n_nonmissing; // number of nonmissing observations
  matrix[11, 33] S_trend1; // mgcv smooth penalty matrix S_trend1
  matrix[12, 36] S_trend2; // mgcv smooth penalty matrix S_trend2
  matrix[12, 36] S_trend3; // mgcv smooth penalty matrix S_trend3
  matrix[12, 36] S_trend4; // mgcv smooth penalty matrix S_trend4
  matrix[12, 36] S_trend5; // mgcv smooth penalty matrix S_trend5
  array[n_nonmissing] int<lower=0> flat_ys; // flattened nonmissing observations
  matrix[n_nonmissing, num_basis] flat_xs; // X values for nonmissing observations
  array[n_nonmissing] int<lower=0> obs_ind; // indices of nonmissing observations
  array[9] int trend_rand_idxs; // trend random effect indices
}
transformed data {
  // exchangeable partial autocorrelation hyperparameters
  // see Heaps 2022 for details (https://doi.org/10.1080/10618600.2022.2079648)
  vector[2] es;
  vector<lower=0>[2] fs;
  vector<lower=0>[2] gs;
  vector<lower=0>[2] hs;
  es[1] = 0;
  es[2] = 0;
  fs[1] = sqrt(0.455);
  fs[2] = sqrt(0.455);
  gs[1] = 1.365;
  gs[2] = 1.365;
  hs[1] = 0.071175;
  hs[2] = 0.071175;
}
parameters {
  // raw basis coefficients
  vector[num_basis] b_raw;
  vector[num_basis_trend] b_raw_trend;
  
  // trend random effects
  vector<lower=0>[1] sigma_raw_trend;
  vector[1] mu_raw_trend;
  
  // latent state variance parameters
  cholesky_factor_corr[n_lv] L_Omega;
  vector<lower=0.2, upper=1>[n_lv] sigma;
  
  // unconstrained VAR1 partial autocorrelations
  matrix[n_lv, n_lv] P_real;
  
  // partial autocorrelation hyperparameters
  vector[2] Pmu;
  vector<lower=0>[2] Pomega;
  
  // latent states
  array[n] vector[n_lv] LV;
  
  // smoothing parameters
  vector<lower=0>[n_sp_trend] lambda_trend;
}
transformed parameters {
  // latent state VAR1 autoregressive terms
  matrix[n_lv, n_lv] A;
  
  // LKJ form of covariance matrix
  matrix[n_lv, n_lv] L_Sigma;
  
  // computed error covariance matrix
  cov_matrix[n_lv] Sigma;
  
  // initial trend covariance
  cov_matrix[n_lv] Gamma;
  
  // basis coefficients
  vector[num_basis] b;
  vector[num_basis_trend] b_trend;
  
  // latent states and loading matrix
  vector[n * n_lv] trend_mus;
  matrix[n, n_series] trend;
  matrix[n_series, n_lv] lv_coefs;
  
  // process model basis coefficients
  b_trend[1 : 59] = b_raw_trend[1 : 59];
  b_trend[60 : 68] = mu_raw_trend[1]
                     + b_raw_trend[60 : 68] * sigma_raw_trend[1];
  
  // latent process linear predictors
  trend_mus = X_trend * b_trend;
  
  // derived latent states
  lv_coefs = Z;
  for (i in 1 : n) {
    for (s in 1 : n_series) {
      trend[i, s] = dot_product(lv_coefs[s,  : ], LV[i]);
    }
  }
  
  L_Sigma = diag_pre_multiply(sigma, L_Omega);
  Sigma = multiply_lower_tri_self_transpose(L_Sigma);
  
  // stationary VAR reparameterisation
  {
    array[1] matrix[n_lv, n_lv] P;
    array[2, 1] matrix[n_lv, n_lv] phiGamma;
    P[1] = P_realtoP(P_real);
    phiGamma = rev_mapping(P, Sigma);
    A = phiGamma[1, 1];
    Gamma = phiGamma[2, 1];
  }
  
  // observation model basis coefficients
  b[1 : num_basis] = b_raw[1 : num_basis];
}
model {
  // latent state mean parameters
  array[n] vector[n_series] mu;
  
  // prior for (Intercept)...
  b_raw[1] ~ normal(0, 0.001);
  
  // priors for latent state variance parameters
  sigma ~ beta(10, 10);
  
  // LKJ error correlation prior
  L_Omega ~ lkj_corr_cholesky(2);
  
  // partial autocorrelation hyperpriors
  Pmu ~ normal(es, fs);
  Pomega ~ gamma(gs, hs);
  
  // unconstrained partial autocorrelations
  diagonal(P_real) ~ normal(Pmu[1], 1 / sqrt(Pomega[1]));
  for (i in 1 : n_lv) {
    for (j in 1 : n_lv) {
      if (i != j) 
        P_real[i, j] ~ normal(Pmu[2], 1 / sqrt(Pomega[2]));
    }
  }
  
  // latent state means
  for (i in 2 : n) {
    mu[i] = A * (LV[i - 1] - trend_mus[ytimes_trend[i - 1, 1 : n_lv]]);
  }
  
  // dynamic process models
  // prior for te(mintemp,lag)_trend...
  b_raw_trend[1 : 11] ~ multi_normal_prec(zero_trend[1 : 11],
                                          S_trend1[1 : 11, 1 : 11]
                                          * lambda_trend[1]
                                          + S_trend1[1 : 11, 12 : 22]
                                            * lambda_trend[2]
                                          + S_trend1[1 : 11, 23 : 33]
                                            * lambda_trend[3]);
                                            
  // prior for te(mintemp,lag):weights_dm_trend...
  b_raw_trend[12 : 23] ~ multi_normal_prec(zero_trend[12 : 23],
                                           S_trend2[1 : 12, 1 : 12]
                                           * lambda_trend[4]
                                           + S_trend2[1 : 12, 13 : 24]
                                             * lambda_trend[5]
                                           + S_trend2[1 : 12, 25 : 36]
                                             * lambda_trend[6]);
                                             
  // prior for te(mintemp,lag):weights_do_trend...
  b_raw_trend[24 : 35] ~ multi_normal_prec(zero_trend[24 : 35],
                                           S_trend3[1 : 12, 1 : 12]
                                           * lambda_trend[7]
                                           + S_trend3[1 : 12, 13 : 24]
                                             * lambda_trend[8]
                                           + S_trend3[1 : 12, 25 : 36]
                                             * lambda_trend[9]);
                                             
  // prior for te(mintemp,lag):weights_ot_trend...
  b_raw_trend[36 : 47] ~ multi_normal_prec(zero_trend[36 : 47],
                                           S_trend4[1 : 12, 1 : 12]
                                           * lambda_trend[10]
                                           + S_trend4[1 : 12, 13 : 24]
                                             * lambda_trend[11]
                                           + S_trend4[1 : 12, 25 : 36]
                                             * lambda_trend[12]);
                                             
  // prior for te(mintemp,lag):weights_pp_trend...
  b_raw_trend[48 : 59] ~ multi_normal_prec(zero_trend[48 : 59],
                                           S_trend5[1 : 12, 1 : 12]
                                           * lambda_trend[13]
                                           + S_trend5[1 : 12, 13 : 24]
                                             * lambda_trend[14]
                                           + S_trend5[1 : 12, 25 : 36]
                                             * lambda_trend[15]);
                                             
  // process model priors                                           
  lambda_trend ~ normal(10, 25);
  sigma_raw_trend ~ inv_gamma(2.3693353, 0.7311319);
  mu_raw_trend ~ std_normal();
  b_raw_trend[trend_rand_idxs] ~ std_normal();
  LV[1] ~ multi_normal(trend_mus[ytimes_trend[1, 1 : n_lv]], Gamma);
  for (i in 2 : n) {
    LV[i] ~ multi_normal_cholesky(trend_mus[ytimes_trend[i, 1 : n_lv]] + mu[i],
                                  L_Sigma);
  }
  
  {
    // likelihood functions
    vector[n_nonmissing] flat_trends;
    flat_trends = to_vector(trend)[obs_ind];
    flat_ys ~ poisson_log_glm(append_col(flat_xs, flat_trends), 0.0,
                              append_row(b, 1.0));
  }
}
generated quantities {
  vector[total_obs] eta;
  matrix[n, n_series] mus;
  vector[n_sp_trend] rho_trend;
  array[n, n_series] int ypred;
  rho_trend = log(lambda_trend);
  
  // posterior predictions
  eta = X * b;
  for (s in 1 : n_series) {
    mus[1 : n, s] = eta[ytimes[1 : n, s]] + trend[1 : n, s];
    ypred[1 : n, s] = poisson_log_rng(mus[1 : n, s]);
  }
}
